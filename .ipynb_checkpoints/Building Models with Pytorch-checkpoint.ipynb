{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "384e3386-9f5e-41f0-8955-3b044234410d",
   "metadata": {},
   "source": [
    "## Building Models with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a357e74-7dc0-41ce-a3c4-01342e709eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model:\n",
      "TinyModel(\n",
      "  (linear1): Linear(in_features=100, out_features=200, bias=True)\n",
      "  (activation): ReLU()\n",
      "  (linear2): Linear(in_features=200, out_features=10, bias=True)\n",
      "  (softmax): Softmax(dim=None)\n",
      ")\n",
      "\n",
      "\n",
      "Just one layer:\n",
      "Linear(in_features=200, out_features=10, bias=True)\n",
      "\n",
      "\n",
      "Model params:\n",
      "Parameter containing:\n",
      "tensor([[-0.0085,  0.0349,  0.0160,  ..., -0.0355,  0.0772, -0.0134],\n",
      "        [-0.0783, -0.0797,  0.0225,  ...,  0.0625,  0.0677, -0.0286],\n",
      "        [ 0.0551,  0.0937, -0.0294,  ..., -0.0592, -0.0295, -0.0467],\n",
      "        ...,\n",
      "        [ 0.0701, -0.0813,  0.0711,  ..., -0.0994, -0.0913,  0.0581],\n",
      "        [ 0.0662, -0.0297, -0.0173,  ..., -0.0757,  0.0138,  0.0620],\n",
      "        [ 0.0345, -0.0019,  0.0994,  ..., -0.0382, -0.0785,  0.0554]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0761,  0.0693,  0.0730, -0.0894,  0.0522, -0.0944, -0.0292, -0.0885,\n",
      "         0.0325,  0.0445,  0.0988,  0.0688, -0.0747, -0.0011, -0.0867, -0.0341,\n",
      "        -0.0112,  0.0878, -0.0297,  0.0405, -0.0495, -0.0925, -0.0329,  0.0044,\n",
      "        -0.0586,  0.0435,  0.0136,  0.0302,  0.0307,  0.0113,  0.0514, -0.0716,\n",
      "        -0.0591, -0.0316, -0.0824,  0.0889, -0.0299,  0.0813, -0.0525, -0.0148,\n",
      "        -0.0214,  0.0090, -0.0042,  0.0421, -0.0043,  0.0099, -0.0803, -0.0426,\n",
      "        -0.0307,  0.0524,  0.0704,  0.0700, -0.0698,  0.0203, -0.0216, -0.0378,\n",
      "         0.0204, -0.0979, -0.0440, -0.0299, -0.0887,  0.0556, -0.0537, -0.0510,\n",
      "         0.0994,  0.0768, -0.0282, -0.0533, -0.0302, -0.0108, -0.0076,  0.0976,\n",
      "         0.0690, -0.0431,  0.0548, -0.0577, -0.0246, -0.0878, -0.0376, -0.0269,\n",
      "        -0.0643, -0.0181, -0.0622, -0.0938,  0.0321,  0.0144,  0.0561, -0.0187,\n",
      "        -0.0376, -0.0283, -0.0334,  0.0893,  0.0143, -0.0546,  0.0357, -0.0033,\n",
      "        -0.0188, -0.0850, -0.0171, -0.0731,  0.0897, -0.0372, -0.0519, -0.0639,\n",
      "         0.0997,  0.0844,  0.0891, -0.0713, -0.0920,  0.0145,  0.0064,  0.0175,\n",
      "         0.0018, -0.0107, -0.0823, -0.0454,  0.0648, -0.0292, -0.0756,  0.0852,\n",
      "        -0.0162,  0.0157,  0.0388,  0.0933, -0.0629,  0.0320, -0.0884,  0.0186,\n",
      "        -0.0687,  0.0672, -0.0870, -0.0737, -0.0360,  0.0405, -0.0235, -0.0428,\n",
      "         0.0961, -0.0797, -0.0783,  0.0969,  0.0088,  0.0409,  0.0283, -0.0571,\n",
      "         0.0545,  0.0352, -0.0473, -0.0766, -0.0347, -0.0103,  0.0500, -0.0407,\n",
      "        -0.0011,  0.0501,  0.0699, -0.0362,  0.0533, -0.0788,  0.0566, -0.0821,\n",
      "        -0.0781,  0.0371,  0.0297, -0.0812,  0.0944,  0.0565, -0.0260,  0.0482,\n",
      "        -0.0959,  0.0949,  0.0007,  0.0527, -0.0413, -0.0842,  0.0771, -0.0477,\n",
      "         0.0864, -0.0522, -0.0888, -0.0740, -0.0968,  0.0596,  0.0658, -0.0029,\n",
      "         0.0021, -0.0461, -0.0649,  0.0681,  0.0538, -0.0645, -0.0295, -0.0878,\n",
      "        -0.0447, -0.0442,  0.0493,  0.0247, -0.0483,  0.0473, -0.0731, -0.0586],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0642, -0.0587,  0.0116,  ..., -0.0587, -0.0284, -0.0397],\n",
      "        [ 0.0604,  0.0214,  0.0599,  ...,  0.0510, -0.0094, -0.0685],\n",
      "        [ 0.0269,  0.0393,  0.0056,  ...,  0.0056,  0.0225,  0.0303],\n",
      "        ...,\n",
      "        [-0.0178, -0.0335, -0.0577,  ..., -0.0084,  0.0602,  0.0220],\n",
      "        [-0.0134,  0.0130,  0.0311,  ..., -0.0702,  0.0307,  0.0533],\n",
      "        [-0.0138,  0.0660,  0.0388,  ..., -0.0666, -0.0675, -0.0490]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0698,  0.0079,  0.0447, -0.0403, -0.0613,  0.0292,  0.0078,  0.0308,\n",
      "         0.0438,  0.0459], requires_grad=True)\n",
      "\n",
      "\n",
      "Layer params:\n",
      "Parameter containing:\n",
      "tensor([[-0.0642, -0.0587,  0.0116,  ..., -0.0587, -0.0284, -0.0397],\n",
      "        [ 0.0604,  0.0214,  0.0599,  ...,  0.0510, -0.0094, -0.0685],\n",
      "        [ 0.0269,  0.0393,  0.0056,  ...,  0.0056,  0.0225,  0.0303],\n",
      "        ...,\n",
      "        [-0.0178, -0.0335, -0.0577,  ..., -0.0084,  0.0602,  0.0220],\n",
      "        [-0.0134,  0.0130,  0.0311,  ..., -0.0702,  0.0307,  0.0533],\n",
      "        [-0.0138,  0.0660,  0.0388,  ..., -0.0666, -0.0675, -0.0490]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0698,  0.0079,  0.0447, -0.0403, -0.0613,  0.0292,  0.0078,  0.0308,\n",
      "         0.0438,  0.0459], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "class TinyModel(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(TinyModel, self).__init__()\n",
    "\n",
    "        self.linear1 = torch.nn.Linear(100, 200)\n",
    "        self.activation = torch.nn.ReLU()\n",
    "        self.linear2 = torch.nn.Linear(200, 10)\n",
    "        self.softmax = torch.nn.Softmax()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "tinymodel = TinyModel()\n",
    "\n",
    "print('The model:')\n",
    "print(tinymodel)\n",
    "\n",
    "print('\\n\\nJust one layer:')\n",
    "print(tinymodel.linear2)\n",
    "\n",
    "print('\\n\\nModel params:')\n",
    "for param in tinymodel.parameters():\n",
    "    print(param)\n",
    "\n",
    "print('\\n\\nLayer params:')\n",
    "for param in tinymodel.linear2.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2adc66-477d-41e2-a87c-2623f46ca2ae",
   "metadata": {},
   "source": [
    "# Common Layer Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "935e9fb7-fbb3-4e9b-9efa-1c998733ea59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      "tensor([[0.1287, 0.6205, 0.3450]])\n",
      "\n",
      "\n",
      "Weight and Bias parameters:\n",
      "Parameter containing:\n",
      "tensor([[ 0.2102,  0.0516, -0.3560],\n",
      "        [ 0.4912,  0.4229,  0.3542]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.0425, 0.3420], requires_grad=True)\n",
      "\n",
      "\n",
      "Output:\n",
      "tensor([[-0.0213,  0.7898]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "lin = torch.nn.Linear(3, 2)\n",
    "x = torch.rand(1, 3)\n",
    "print('Input:')\n",
    "print(x)\n",
    "\n",
    "print('\\n\\nWeight and Bias parameters:')\n",
    "for param in lin.parameters():\n",
    "    print(param)\n",
    "\n",
    "y = lin(x)\n",
    "print('\\n\\nOutput:')\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7d9bb8-7e9b-4e06-87ed-ce5dab0d4eb4",
   "metadata": {},
   "source": [
    "# Convolutional Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79400995-2108-4647-bf29-260bbd613d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.functional as F\n",
    "\n",
    "\n",
    "class LeNet(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        # 1 input image channel (black & white), 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = torch.nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = torch.nn.Conv2d(6, 16, 3)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = torch.nn.Linear(16 * 6 * 6, 120)  # 6*6 from image dimension\n",
    "        self.fc2 = torch.nn.Linear(120, 84)\n",
    "        self.fc3 = torch.nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268da336-7bb6-4455-a70c-62e894690eca",
   "metadata": {},
   "source": [
    "# Recurrent Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef0f0503-093b-4339-b16d-c68a04ccd377",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMTagger(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):\n",
    "        super(LSTMTagger, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.word_embeddings = torch.nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
    "        # with dimensionality hidden_dim.\n",
    "        self.lstm = torch.nn.LSTM(embedding_dim, hidden_dim)\n",
    "\n",
    "        # The linear layer that maps from hidden state space to tag space\n",
    "        self.hidden2tag = torch.nn.Linear(hidden_dim, tagset_size)\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        embeds = self.word_embeddings(sentence)\n",
    "        lstm_out, _ = self.lstm(embeds.view(len(sentence), 1, -1))\n",
    "        tag_space = self.hidden2tag(lstm_out.view(len(sentence), -1))\n",
    "        tag_scores = F.log_softmax(tag_space, dim=1)\n",
    "        return tag_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be388045-8749-4f66-b463-cbda7465f8d8",
   "metadata": {},
   "source": [
    "# Other Layers and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7038d3e0-1ae3-46e0-8d74-4cb69caad055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.6983, 0.5676, 0.3204, 0.3889, 0.2355, 0.0178],\n",
      "         [0.5639, 0.4404, 0.8957, 0.7548, 0.6972, 0.7987],\n",
      "         [0.2347, 0.5380, 0.2957, 0.3119, 0.2110, 0.7655],\n",
      "         [0.2671, 0.9940, 0.5068, 0.4995, 0.6809, 0.5198],\n",
      "         [0.0153, 0.3990, 0.1317, 0.2313, 0.6939, 0.5924],\n",
      "         [0.4912, 0.8588, 0.6735, 0.7419, 0.3084, 0.1327]]])\n",
      "tensor([[[0.8957, 0.7987],\n",
      "         [0.9940, 0.7419]]])\n"
     ]
    }
   ],
   "source": [
    "# Data Manipulation Layers\n",
    "my_tensor = torch.rand(1, 6, 6)\n",
    "print(my_tensor)\n",
    "\n",
    "maxpool_layer = torch.nn.MaxPool2d(3)\n",
    "print(maxpool_layer(my_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90b2995c-1f3e-40e3-95ae-23a7c0b6f2fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[17.3654,  9.0746, 22.6011,  9.3096],\n",
      "         [22.8575, 14.2060, 14.2112, 12.7853],\n",
      "         [12.9372, 11.3995, 22.6575, 23.4359],\n",
      "         [13.5261, 21.2151, 15.7056, 16.6480]]])\n",
      "tensor(16.2460)\n",
      "tensor([[[ 0.4869, -0.9664,  1.4047, -0.9252],\n",
      "         [ 1.7136, -0.4530, -0.4517, -0.8088],\n",
      "         [-0.8533, -1.1343,  0.9227,  1.0649],\n",
      "         [-1.1586,  1.5845, -0.3810, -0.0448]]],\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "tensor(8.9407e-08, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "my_tensor = torch.rand(1, 4, 4) * 20 + 5\n",
    "print(my_tensor)\n",
    "\n",
    "print(my_tensor.mean())\n",
    "\n",
    "norm_layer = torch.nn.BatchNorm1d(4)\n",
    "normed_tensor = norm_layer(my_tensor)\n",
    "print(normed_tensor)\n",
    "\n",
    "print(normed_tensor.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31484811-83ef-4458-a0fe-4b3f42e59eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.2621, 0.0000, 0.0000, 0.0000],\n",
      "         [0.3003, 0.1985, 0.0000, 0.0000],\n",
      "         [1.0800, 0.2400, 1.1547, 1.1543],\n",
      "         [0.9552, 0.9490, 1.6352, 0.0000]]])\n",
      "tensor([[[0.2621, 0.0177, 0.0000, 0.1951],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [1.0800, 0.2400, 0.0000, 1.1543],\n",
      "         [0.9552, 0.9490, 1.6352, 0.0000]]])\n"
     ]
    }
   ],
   "source": [
    "my_tensor = torch.rand(1, 4, 4)\n",
    "\n",
    "dropout = torch.nn.Dropout(p=0.4)\n",
    "print(dropout(my_tensor))\n",
    "print(dropout(my_tensor))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
